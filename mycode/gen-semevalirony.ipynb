{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Irony data\n",
    "\n",
    "**Table of contents**:\n",
    "- Qwen/Qwen2.5-0.5B-Instruct\n",
    "    1. Baseline\n",
    "    2. Targeted\n",
    "    3. Targeted + Linguistic tags\n",
    "- deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "    1. Baseline\n",
    "    2. Targeted\n",
    "    3. Targeted + Linguistic tags\n",
    "\n",
    "**Results**:\n",
    "- irony seems a too difficult topic for this models, the \"irony\" sentences aren't ironic (also the \"targeted\" prompts case).\n",
    "- doesn't follow always the instruction and is very sensitive to prompt, but it follows nicely the JSON format.\n",
    "- ChatGPT gives examples that are actually ironic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>seeing ppl walking w/ crutches makes me really...</td>\n",
       "      <td>irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>look for the girl with the broken smile, ask h...</td>\n",
       "      <td>non irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Now I remember why I buy books online @user #s...</td>\n",
       "      <td>irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@user @user So is he banded from wearing the c...</td>\n",
       "      <td>irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just found out there are Etch A Sketch apps.  ...</td>\n",
       "      <td>irony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                               text      label\n",
       "0  0  seeing ppl walking w/ crutches makes me really...      irony\n",
       "1  1  look for the girl with the broken smile, ask h...  non irony\n",
       "2  2  Now I remember why I buy books online @user #s...      irony\n",
       "3  3  @user @user So is he banded from wearing the c...      irony\n",
       "4  4  Just found out there are Etch A Sketch apps.  ...      irony"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First irony example:\n",
      "seeing ppl walking w/ crutches makes me really excited for the next 3 weeks of my life\n",
      "\n",
      "First non irony example:\n",
      "look for the girl with the broken smile, ask her if she wants to stay while, and she will be loved. ðŸ’•ðŸŽµ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Move up one directory\n",
    "if os.path.basename(os.getcwd()) == \"mycode\":\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from mycode.utilities import log_synthetic_data, response2json, get_response, set_seed, clear_cuda_cache\n",
    "\n",
    "# Create the folder to save the synthetic data\n",
    "folder_name = \"synthetic_data\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# file where the logs will be saved\n",
    "log_file_path = \"synthetic_data/semevalirony_log.json\"\n",
    "if os.path.exists(log_file_path):\n",
    "    os.remove(log_file_path)\n",
    "\n",
    "# device\n",
    "device = 'cuda:0'\n",
    "\n",
    "# DATA\n",
    "df = pd.read_csv(\"LREC-COLING/train/semevalironytrainAll.csv\")\n",
    "df = df.rename(columns={\"1\": \"text\", \"2\": \"label\"})\n",
    "display(df.head())\n",
    "first_irony = df[df['label'] == 'irony'].iloc[0].loc['text']\n",
    "first_non_irony = df[df['label'] == 'non-irony'].iloc[0].loc['text']\n",
    "\n",
    "print(\"\\nFirst irony example:\")\n",
    "print(first_irony)\n",
    "\n",
    "print(\"\\nFirst non-irony example:\")\n",
    "print(first_non_irony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen/Qwen2.5-0.5B-Instruct\n",
    "## 1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\",\n",
    "    attn_implementation='flash_attention_2',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# for qwen we use this system prompt:\n",
    "system_prompt_qwen = \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 1.16\n",
      "GENERATED RESPONSE:\n",
      "I'm ready to assist you with your request! Please provide me with the text and label for each example.\n"
     ]
    }
   ],
   "source": [
    "prompt =\"\"\"\\\n",
    "Produce 10 examples for detecting irony in written text. Examples are categorized as either \"irony\" or \"non-irony\". \\\n",
    "Produce 5 examples  for \"irony\" and 5 examples for \"non-irony\". \n",
    "\n",
    "Use this format for the examples:\n",
    "text: <text>\n",
    "label: <label>\n",
    "\"\"\"\n",
    "generated, delta_t = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 0.85\n",
      "GENERATED RESPONSE:\n",
      "text: Seeing people walking with crutches makes me super excited about the next three weeks of my life.\n",
      "Label: irony\n",
      "\n",
      "text: Look for the girl with the broken smile, ask her if she wants to stay, and she will be loved. ðŸ•ºðŸ’–\n",
      "Label: non irony\n"
     ]
    }
   ],
   "source": [
    "# With example for the two classes\n",
    "prompt =f\"\"\"\\\n",
    "Produce 10 examples for detecting irony in written text. Examples are categorized as either \"irony\" or \"non-irony\". \\\n",
    "Produce exactly 5 examples  for \"irony\" and 5 examples for \"non-irony\". \n",
    "\n",
    "Use this format for generating the data:\n",
    "text: {first_irony}\n",
    "label: irony\n",
    "\n",
    "text: {first_non_irony}\n",
    "label: non-irony\n",
    "\"\"\"\n",
    "generated, delta_t = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 5.07\n",
      "GENERATED RESPONSE:\n",
      "Sure! Here are ten examples that I've generated to detect irony in written text:\n",
      "\n",
      "### Irony Example 1\n",
      "> \"I was so excited about my new job that I couldn't contain myself and burst into tears.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 2\n",
      "> \"The cat chased the mouse but the mouse didnâ€™t care because it knew the cat would eat it.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 3\n",
      "> \"He said he would go on a vacation next week, but he never showed up at all.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 4\n",
      "> \"She told me she would come over for dinner, but when she arrived, she wasn't even there.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 5\n",
      "> \"The judge ruled that the defendant should be sentenced to life imprisonment.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 6\n",
      "> \"The politician promised to vote for the bill, but when they voted, they changed their minds.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 7\n",
      "> \"The teacher explained the rules of the game, but the players didn't understand.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 8\n",
      "> \"The customer complained about the quality of the product, but the salesperson ignored his complaint.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 9\n",
      "> \"The company announced its plans for the future, but the CEO refused to listen.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "### Irony Example 10\n",
      "> \"The weather forecast predicted clear skies, but it rained heavily.\"\n",
      "\n",
      "**Label:** Irony\n",
      "\n",
      "These examples aim to showcase different scenarios where the expected outcome did not occur as intended, indicating an ironic situation rather than a genuine or logical statement.\n"
     ]
    }
   ],
   "source": [
    "# act as a linguist and NLP practitioner\n",
    "prompt =f\"\"\"\\\n",
    "You are an expert linguist and NLP practitioner specializing in irony detection. \\\n",
    "Your task is to generate high-quality synthetic examples of ironic and non-ironic text to improve an irony detection model\n",
    "\n",
    "Produce 10 examples for detecting irony in written text. Examples are categorized as either \"irony\" or \"non-irony\". \\\n",
    "Produce exactly 5 examples for \"irony\" and 5 examples for \"non-irony\". \n",
    "\n",
    "Use this format for generating the data:\n",
    "text: <text>\n",
    "label: <label>\n",
    "\"\"\"\n",
    "generated, delta_t = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 2.91\n",
      "GENERATED RESPONSE:\n",
      "Here are ten examples of \"irony\" and \"non-irony\" statements with five each:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"text\": \"I'm so hungry, but I don't have any food at home.\",\n",
      "        \"label\": \"irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The sun was shining and I decided to go for a walk.\",\n",
      "        \"label\": \"non-irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"He's going on a date with someone new, and he looks really good.\",\n",
      "        \"label\": \"irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The sky is blue today, but it's raining.\",\n",
      "        \"label\": \"non-irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I forgot about my appointment, but I'm not late.\",\n",
      "        \"label\": \"irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She just told me she's going on a trip next week.\",\n",
      "        \"label\": \"non-irony\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP practitioner specializing in irony detection. \\\n",
    "Your task is to generate **10 high-quality examples** of \"irony\" and \"non-irony\" statements, \\\n",
    "with **5 irony** and **5 non-irony** examples across different contexts.\n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return only a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": \"{first_irony}\", \"label\": \"irony\"}},\n",
    "    {{\"text\": \"{first_non_irony}\", \"label\": \"non-irony\"}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_data[:2]:  [{'text': \"I'm so hungry, but I don't have any food at home.\", 'label': 'irony'}, {'text': 'The sun was shining and I decided to go for a walk.', 'label': 'non-irony'}]\n"
     ]
    }
   ],
   "source": [
    "synthetic_data = response2json(response)\n",
    "\n",
    "print(\"synthetic_data[:2]: \", synthetic_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged 6 examples to synthetic_data/semevalirony_log.json. Time taken: 2.91 seconds\n",
      "[\n",
      "    {\n",
      "        \"timestamp\": \"2025-03-10T12:41:44.032109\",\n",
      "        \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
      "        \"generation_method\": \"baseline\",\n",
      "        \"prompt\": \"You are an expert linguist and NLP practitioner specializing in irony detection. Your task is to generate **10 high-quality examples** of \\\"irony\\\" and \\\"non irony\\\" statements, with **5 irony** and **5 non irony** examples across different contexts.\\n\\n### **Output Format (JSON)**\\nReturn only a valid JSON list in the following structure:\\n\\n```json\\n[\\n    {\\\"text\\\": \\\"seeing ppl walking w/ crutches makes me really excited for the next 3 weeks of my life\\\", \\\"label\\\": \\\"irony\\\"},\\n    {\\\"text\\\": \\\"look for the girl with the broken smile, ask her if she wants to stay while, and she will be loved. ðŸ’•ðŸŽµ\\\", \\\"label\\\": \\\"non irony\\\"},\\n    ...\\n]\\n```\\n\",\n",
      "        \"time_taken_seconds\": 2.91,\n",
      "        \"num_examples\": 6,\n",
      "        \"generated_examples\": [\n",
      "            {\n",
      "                \"text\": \"I'm so hungry, but I don't have any food at home.\",\n",
      "                \"label\": \"irony\"\n",
      "            },\n",
      "            {\n",
      "                \"text\": \"The sun was shining and I decided to go for a walk.\",\n",
      "                \"label\": \"non-irony\"\n",
      "            },\n",
      "            {\n",
      "                \"text\": \"He's going on a date with someone new, and he looks really good.\",\n",
      "                \"label\": \"irony\"\n",
      "            },\n",
      "            {\n",
      "                \"text\": \"The sky is blue today, but it's raining.\",\n",
      "                \"label\": \"non-irony\"\n",
      "            },\n",
      "            {\n",
      "                \"text\": \"I forgot about my appointment, but I'm not late.\",\n",
      "                \"label\": \"irony\"\n",
      "            },\n",
      "            {\n",
      "                \"text\": \"She just told me she's going on a trip next week.\",\n",
      "                \"label\": \"non-irony\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "log_synthetic_data(model_name, \"baseline\", prompt, synthetic_data, delta_t, output_file=log_file_path)\n",
    "\n",
    "# Load JSON file\n",
    "with open(log_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Print the first log entry\n",
    "print(json.dumps(data[:1], indent=4, ensure_ascii=False))  # Pretty-print the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model</th>\n",
       "      <th>generation_method</th>\n",
       "      <th>prompt</th>\n",
       "      <th>time_taken_seconds</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-10T12:41:44.032109</td>\n",
       "      <td>Qwen/Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>baseline</td>\n",
       "      <td>You are an expert linguist and NLP practitione...</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6</td>\n",
       "      <td>I'm so hungry, but I don't have any food at home.</td>\n",
       "      <td>irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-10T12:41:44.032109</td>\n",
       "      <td>Qwen/Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>baseline</td>\n",
       "      <td>You are an expert linguist and NLP practitione...</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6</td>\n",
       "      <td>The sun was shining and I decided to go for a ...</td>\n",
       "      <td>non-irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-10T12:41:44.032109</td>\n",
       "      <td>Qwen/Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>baseline</td>\n",
       "      <td>You are an expert linguist and NLP practitione...</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6</td>\n",
       "      <td>He's going on a date with someone new, and he ...</td>\n",
       "      <td>irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-10T12:41:44.032109</td>\n",
       "      <td>Qwen/Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>baseline</td>\n",
       "      <td>You are an expert linguist and NLP practitione...</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6</td>\n",
       "      <td>The sky is blue today, but it's raining.</td>\n",
       "      <td>non-irony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-10T12:41:44.032109</td>\n",
       "      <td>Qwen/Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>baseline</td>\n",
       "      <td>You are an expert linguist and NLP practitione...</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6</td>\n",
       "      <td>I forgot about my appointment, but I'm not late.</td>\n",
       "      <td>irony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp                       model generation_method  \\\n",
       "0  2025-03-10T12:41:44.032109  Qwen/Qwen2.5-0.5B-Instruct          baseline   \n",
       "1  2025-03-10T12:41:44.032109  Qwen/Qwen2.5-0.5B-Instruct          baseline   \n",
       "2  2025-03-10T12:41:44.032109  Qwen/Qwen2.5-0.5B-Instruct          baseline   \n",
       "3  2025-03-10T12:41:44.032109  Qwen/Qwen2.5-0.5B-Instruct          baseline   \n",
       "4  2025-03-10T12:41:44.032109  Qwen/Qwen2.5-0.5B-Instruct          baseline   \n",
       "\n",
       "                                              prompt  time_taken_seconds  \\\n",
       "0  You are an expert linguist and NLP practitione...                2.91   \n",
       "1  You are an expert linguist and NLP practitione...                2.91   \n",
       "2  You are an expert linguist and NLP practitione...                2.91   \n",
       "3  You are an expert linguist and NLP practitione...                2.91   \n",
       "4  You are an expert linguist and NLP practitione...                2.91   \n",
       "\n",
       "   num_examples                                               text      label  \n",
       "0             6  I'm so hungry, but I don't have any food at home.      irony  \n",
       "1             6  The sun was shining and I decided to go for a ...  non-irony  \n",
       "2             6  He's going on a date with someone new, and he ...      irony  \n",
       "3             6           The sky is blue today, but it's raining.  non-irony  \n",
       "4             6   I forgot about my appointment, but I'm not late.      irony  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert log entries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Expand the 'generated_examples' column\n",
    "samples_df = df.explode(\"generated_examples\").reset_index(drop=True)\n",
    "\n",
    "# Convert 'generated_examples' (which is still a dictionary) into separate columns\n",
    "samples_df = pd.concat([samples_df.drop(columns=[\"generated_examples\"]), samples_df[\"generated_examples\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "display(samples_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Targeted synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 13.87\n",
      "GENERATED RESPONSE:\n",
      "Certainly! Here is a comprehensive list of key linguistic and semantic phenomena that need to be covered for an ironic detection model:\n",
      "\n",
      "### Linguistic Phenomena\n",
      "\n",
      "1. **Word Choice**:\n",
      "   - **Example**: \"The quick brown fox jumps over the lazy dog.\"\n",
      "     - This sentence uses hyperbole (\"quick\" being very fast) and metaphorical language (\"jumps over the lazy dog\") to convey sarcasm.\n",
      "\n",
      "2. **Phonological Variation**:\n",
      "   - **Example**: \"She said 'I'm so hungry.'\"\n",
      "     - The word order in this sentence (e.g., \"I'm so hungry.\") is inverted, which can indicate sarcasm or misinterpretation.\n",
      "\n",
      "3. **Pronunciation and Spelling**:\n",
      "   - **Example**: \"It's raining cats and dogs outside.\"\n",
      "     - The spelling error (\"cats and dogs\" instead of \"cats and dogs\") could be a form of irony, suggesting a misunderstanding or exaggeration.\n",
      "\n",
      "4. **Sentence Structure**:\n",
      "   - **Example**: \"He ate the cake without even knowing it was there.\"\n",
      "     - The lack of clarity in the sentence structure (\"ate without knowing it was there\") implies confusion or misdirection.\n",
      "\n",
      "5. **Grammatical Structures**:\n",
      "   - **Example**: \"I saw the cat in the garden but I didn't catch it.\"\n",
      "     - The use of \"but\" suggests a contrast between what one expected versus what actually happened, indicating irony.\n",
      "\n",
      "6. **Tense and Mood**:\n",
      "   - **Example**: \"I told you not to worry but now I'm worried about you.\"\n",
      "     - The use of past tense (\"told you\") contrasts with the present tense (\"not to worry\").\n",
      "\n",
      "7. **Case and Gender**:\n",
      "   - **Example**: \"He said he would come tomorrow.\"\n",
      "     - The gendered nature of \"he\" in this context indicates that the statement is meant as a joke or play on words, rather than a serious assertion.\n",
      "\n",
      "8. **Prepositional Phrases**:\n",
      "   - **Example**: \"We should have gone earlier because we had to wait in line.\"\n",
      "     - The phrase \"because we had to wait in line\" suggests a sarcastic implication of waiting too long.\n",
      "\n",
      "9. **Adverbial Phrases**:\n",
      "   - **Example**: \"She ran faster than the fastest runner in her school.\"\n",
      "     - The adverb \"faster than\" implies that she surpassed someone else in speed, which could be seen as a form of irony.\n",
      "\n",
      "10. **Conjunctions and Prepositions**:\n",
      "    - **Example**: \"They went to the park but then they came back late.\"\n",
      "      - The use of conjunctions like \"but\" and prepositions like \"then\" can suggest a shift in meaning or emphasis.\n",
      "\n",
      "### Semantic Phenomena\n",
      "\n",
      "1. **Contextual Clues**:\n",
      "   - **Example**: \"He said, 'I'm so hungry.'\"\n",
      "     - The explicit mention of hunger in the first person singular pronoun (\"I'm\") creates a strong link between the speaker and the event described.\n",
      "\n",
      "2. **Emotional Tone**:\n",
      "   - **Example**: \"She looked at him with tears in her eyes.\"\n",
      "     - The emotional tone of sadness (\"tears in her eyes\") could indicate irony if the intention behind the action wasn't clear.\n",
      "\n",
      "3. **Cultural Nuances**:\n",
      "   - **Example**: \"He said, 'I'm so hungry.'\"\n",
      "     - The cultural nuance of \"hungry\" in different cultures can lead to misunderstandings, which might be interpreted as irony.\n",
      "\n",
      "4. **Dialectal Variations**:\n",
      "   - **Example**: \"He said, 'I'm so hungry.'\"\n",
      "     - Different dialects might interpret this differently, leading to various interpretations of irony.\n",
      "\n",
      "5. **Historical Context**:\n",
      "   - **Example**: \"He said, 'I'm so hungry.'\"\n",
      "     - Historical contexts might explain why the exact wording is used, such as when discussing historical events where hunger is a significant factor.\n",
      "\n",
      "6. **Literary Devices**:\n",
      "   - **Example**: \"He said, 'I'm so hungry.'\"\n",
      "     - Literary devices like repetition (\"I'm so hungry.\"), metaphor (\"I'm so hungry.\"), or simile (\"I'm so hungry.\") can contribute to the irony.\n",
      "\n",
      "7. **Symbolism and Allegory**:\n",
      "   - **Example**: \"He said, 'I'm so hungry.'\"\n",
      "     - Symbolic elements (\"hunger,\" \"fastness,\" \"waiting\") can create a deeper layer of irony, making the statement more complex.\n",
      "\n",
      "8. **Personification**:\n",
      "   - **Example**: \"He said, 'I'm so hungry.'\"\n",
      "     - Personification (\"I'm so hungry.\") can add a sense of human emotion or consciousness to the statement, further complicating its interpretation.\n",
      "\n",
      "By covering these linguistic and semantic phenomena, an ironic detection model can effectively identify and analyze situations where the intended message seems contradictory or exaggerated due to contextual cues, cultural nuances, or other factors.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP practitioner. \\\n",
    "List all key linguistic and semantic phenomena that must be covered by a irony detection model to perform accurately. \\\n",
    "Provide concrete examples illustrating each phenomenon. \\\n",
    "\"\"\"\n",
    "response, delta_t_0 = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 0.4\n",
      "GENERATED RESPONSE:\n",
      "- Irony Detection\n",
      "- Semantic Analysis\n",
      "- Contrast Detection\n",
      "- Pragmatic Inference\n",
      "- Negation\n",
      "- Sarcasm\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP practitioner. \\\n",
    "List all key linguistic and semantic phenomena that must be considered for an irony detection model to perform accurately. \\\n",
    "Provide only the names of these phenomena as a structured list, without explanations. \\\n",
    "For example: sarcasm, negation, pragmatic inference, unexpected contrast. \\\n",
    "Return the list in a simple bullet-point format.\\\n",
    "\"\"\"\n",
    "response, delta_t_0 = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 4.24\n",
      "GENERATED RESPONSE:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"text\": \"The cat was sleeping on the couch when the dog walked over it.\",\n",
      "        \"label\": \"irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"He said he would meet you at the park but then he forgot about it.\",\n",
      "        \"label\": \"non irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I had to leave early because I was running late, so I decided to go home.\",\n",
      "        \"label\": \"irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She said she wanted to go to the party but then realized she didn't have any money.\",\n",
      "        \"label\": \"non irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The company is going through a difficult time, so they need all the help they can get.\",\n",
      "        \"label\": \"irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The movie was terrible, but I still enjoyed it because I'm a big fan.\",\n",
      "        \"label\": \"non irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The sun was shining brightly today, so everyone went outside for a picnic.\",\n",
      "        \"label\": \"irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I was told not to eat too much, but now I feel full.\",\n",
      "        \"label\": \"non irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The sky was blue, so we decided to fly to the top of the mountain.\",\n",
      "        \"label\": \"irony\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Replace \"- \" at the beginning of each line with a comma\n",
    "csv_string = re.sub(r\"^\\s*-\\s*\", \"\", response, flags=re.MULTILINE)  # Remove bullet points\n",
    "csv_string = \", \".join(csv_string.strip().split(\"\\n\"))  # Join lines with \", \"\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "Generate 10 realistic sentences illustrating irony detection examples involving {csv_string}. Ensure that:\n",
    "- 5 sentences are **irony**.\n",
    "- 5 sentences are **non-irony**.\n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return **only** a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": \"{first_irony}\", \"label\": \"irony\"}},\n",
    "    {{\"text\": \"{first_non_irony}\", \"label\": \"non-irony\"}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)\n",
    "# synthetic_data = response2json(response)\n",
    "# log_synthetic_data(model_name, \"targeted\", prompt, synthetic_data, delta_t, output_file=log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted synthetic data with Chat-GPT\n",
    "\n",
    "The topics that need to be covered are generated from Chat-GPT online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 3.99\n",
      "GENERATED RESPONSE:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"text\": \"The cat is everywhere.\",\n",
      "        \"label\": \"Irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I love ice cream, but I don't like chocolate.\",\n",
      "        \"label\": \"Non-irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She always says she'll be here tomorrow, but she's actually going somewhere else.\",\n",
      "        \"label\": \"Irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"We should eat more vegetables, but we're having too many meals.\",\n",
      "        \"label\": \"Non-irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"He said he would come over tonight, but he didn't.\",\n",
      "        \"label\": \"Irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"This movie is great, but it's not really what I expected.\",\n",
      "        \"label\": \"Non-irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"They said they'd go on vacation next year, but they haven't decided yet.\",\n",
      "        \"label\": \"Irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I can't believe you did that, but you're still doing it.\",\n",
      "        \"label\": \"Non-irony\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"He promised he'd finish his homework before bedtime, but he never did.\",\n",
      "        \"label\": \"Irony\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Logged 9 examples to synthetic_data/semevalirony_log.json. Time taken: 3.99 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP practitioner. \\\n",
    "Generate 10 realistic sentences illustrating irony detection examples involving.\n",
    "For each example specify the label as either \"irony\" or \"non-irony\".\n",
    "\n",
    "### **Consider the following Phenomena:**\n",
    "- **Linguistic Phenomena**  \n",
    "    - Lexical Choice: Unusual or exaggerated word use.  \n",
    "    - Negation: Statements that negate obvious facts.  \n",
    "    - Punctuation: Use of exclamation marks, ellipses, or quotes for emphasis.  \n",
    "    - Syntactic Cues: Unusual or complex sentence structures.  \n",
    "    - Contrastive Conjunctions: Use of \"but,\" \"however,\" to signal contradiction.  \n",
    "\n",
    "- **Semantic Phenomena**  \n",
    "    - Contextual Incongruity: Discrepancy between words and context.  \n",
    "    - Polarity Reversal: Positive words with negative intent, or vice versa.  \n",
    "    - Hyperbole & Understatement: Exaggeration or minimization for effect.  \n",
    "    - Sarcasm: Mocking statements implying the opposite meaning.  \n",
    "\n",
    "- **Contextual Cues**  \n",
    "    - World Knowledge: Understanding cultural or situational references.  \n",
    "    - Speaker Intent: Inferring the true intention behind words.  \n",
    "    - Discourse Contrast: Contradictions across multiple sentences.  \n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return only a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": <text>, \"label\": <label>}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)\n",
    "synthetic_data = response2json(response)\n",
    "log_synthetic_data(model_name, \"targeted\", prompt, synthetic_data, delta_t, output_file=log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Targeted + Tags linguistic phenomena \n",
    "\n",
    "Now we ask to the model also to identify the linguistic phenomena present in the generated sentence.\n",
    "\n",
    "```\n",
    "{  \n",
    "    \"text\": \"Oh, I absolutely adore being stuck in traffic for hours.\",   \n",
    "    \"label\": \"ironic\",  \n",
    "    \"phenomena\": [\"Polarity inversion\", \"Hyperbole\", \"Semantic incongruence\", \"Lexical exaggeration\"]\n",
    "},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 5.32\n",
      "GENERATED RESPONSE:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"text\": \"The company's CEO announced they would be launching a new product.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Lexical Choice\", \"Punctuation\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I'm so tired of this boring lecture.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Negation\", \"Syntactic Cues\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She said she was going on vacation tomorrow.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Negation\", \"Sarcasm\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"He said he couldn't make it to the party.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Negation\", \"Hyperbole & Understatement\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"They will have to work hard to finish the project.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Contextual Incongruity\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"It is raining heavily outside.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Contextual Incongruity\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"We should stop talking about politics.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Contextual Incongruity\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She just got married.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Contextual Incongruity\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"This restaurant has terrible food.\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"Contextual Incongruity\"]\n",
      "    }\n",
      "]\n",
      "```\n",
      "Logged 9 examples to synthetic_data/semevalirony_log.json. Time taken: 5.32 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP specialist in sarcasm and irony detection. \\\n",
    "Generate 10 realistic sentences illustrating irony detection examples.\\\n",
    "For each example specify the label as either \"irony\" or \"non-irony\". And also list the key phenomena it covers.\n",
    "\n",
    "### **Consider the following Phenomena:**\n",
    "- **Linguistic Phenomena**  \n",
    "    - Lexical Choice: Unusual or exaggerated word use.  \n",
    "    - Negation: Statements that negate obvious facts.  \n",
    "    - Punctuation: Use of exclamation marks, ellipses, or quotes for emphasis.  \n",
    "    - Syntactic Cues: Unusual or complex sentence structures.  \n",
    "    - Contrastive Conjunctions: Use of \"but,\" \"however,\" to signal contradiction.  \n",
    "\n",
    "- **Semantic Phenomena**  \n",
    "    - Contextual Incongruity: Discrepancy between words and context.  \n",
    "    - Polarity Reversal: Positive words with negative intent, or vice versa.  \n",
    "    - Hyperbole & Understatement: Exaggeration or minimization for effect.  \n",
    "    - Sarcasm: Mocking statements implying the opposite meaning.  \n",
    "\n",
    "- **Contextual Cues**  \n",
    "    - World Knowledge: Understanding cultural or situational references.  \n",
    "    - Speaker Intent: Inferring the true intention behind words.  \n",
    "    - Discourse Contrast: Contradictions across multiple sentences.  \n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return only a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": <text>, \"label\": <corresponding label>, \"phenomena\": [\"<phenomenon1>\", \"<phenomenon2>\", ...]}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer, system_prompt=system_prompt_qwen)\n",
    "synthetic_data = response2json(response)\n",
    "log_synthetic_data(model_name, \"targeted + linguistic tags\", prompt, synthetic_data, delta_t, output_file=log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "\n",
    "## 1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cuda_cache(model)\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation='flash_attention_2',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# we don't submit a system prompt as suggested in the model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 16.89\n",
      "GENERATED RESPONSE:\n",
      "Okay, so the user has asked me to produce 10 examples of irony in written text, categorizing them into 5 \"irony\" and 5 \"non-irony\" examples. They also provided a specific format for each example, which includes the text and a label.\n",
      "\n",
      "First, I need to make sure I understand what irony is. Irony is when the meaning of a statement is the opposite of its literal meaning. It's often used to express sarcasm or surprise. So, I need to come up with both ironic and non-ironic examples.\n",
      "\n",
      "For the ironic examples, I should think of situations where the punchline or implication is the opposite of what's stated. Maybe a situation where the speaker is saying something that's contrary to what's true, or where the situation is the opposite of what's expected.\n",
      "\n",
      "Let me brainstorm some scenarios. Maybe a situation where something is said that's contrary to fact, like a lie being told truthfully. Or a situation where the opposite of what's expected happens. For example, if someone says, \"I love you, but I hate you,\" and the situation is that they actually love you but hate you, which is contradictory.\n",
      "\n",
      "Another example could be when someone is trying to say something positive but ends up saying something negative because of their perspective. Like a quote that's meant to be positive, but the speaker's context makes it negative.\n",
      "\n",
      "For non-irony examples, I need to think of situations where the statement is neither contrary nor sarcastic. It should be straightforward and not lead to any surprise or sarcasm. Maybe a simple statement about someone's job, like a person's job being \"lackluster,\" which is a common non-ironic statement.\n",
      "\n",
      "I should also consider different contexts, like social situations, historical events, or everyday scenarios. Each example should clearly show whether it's ironic or not.\n",
      "\n",
      "Let me try to come up with some examples. For ironic ones, maybe a situation where the speaker is lying, or their words are contradictory. For non-ironic, perhaps a statement that's just factually correct in a neutral way.\n",
      "\n",
      "I need to make sure each example is clear and that the label is correct. I'll list them out, ensuring that each category has 5 examples. I should also vary the scenarios to cover different subjects and situations to make it comprehensive.\n",
      "\n",
      "Now, I'll draft the examples, making sure each one fits the format and correctly identifies whether it's ironic or non-ironic. I'll double-check each example to ensure it meets the criteria, especially for irony where the opposite of the statement is the intended meaning.\n",
      "\n",
      "Once I have all the examples, I'll present them clearly, numbering them from 1 to 10, and then split them into the two categories. I'll make sure there are no duplicates and that each one accurately reflects the required format.\n",
      "\n",
      "Finally, I'll review the examples to ensure they're diverse and cover different aspects of irony, from social situations to more personal or situational contexts. This way, the user gets a good mix of examples that help them understand both ironic and non-ironic situations.\n",
      "</think>\n",
      "\n",
      "Here are 10 examples of written text, categorized as either \"irony\" or \"non-irony,\" along with the provided format:\n",
      "\n",
      "1. **Irony**: \"You're so cool, but I really admire you.\"  \n",
      "   Label: Irony  \n",
      "\n",
      "2. **Irony**: \"I'm so sorry, but I can't believe it happened.\"  \n",
      "   Label: Irony  \n",
      "\n",
      "3. **Irony**: \"This is a bad day, but I'm so glad I made it.\"  \n",
      "   Label: Irony  \n",
      "\n",
      "4. **Irony**: \"You're not a bad person, but you're so unappreciative.\"  \n",
      "   Label: Irony  \n",
      "\n",
      "5. **Non-Irony**: \"I love you, but I hate you.\"  \n",
      "   Label: Non-Irony  \n",
      "\n",
      "6. **Irony**: \"This is the best day of my life, but I can't believe it happened.\"  \n",
      "   Label: Irony  \n",
      "\n",
      "7. **Irony**: \"You're not a good person, but I'm so glad I made it.\"  \n",
      "   Label: Irony  \n",
      "\n",
      "8. **Non-Irony**: \"The weather is perfect, but I can't believe it's going to rain.\"  \n",
      "   Label: Non-Irony  \n",
      "\n",
      "9. **Irony**: \"This is a bad day, but I'm so glad I didn't make it.\"  \n",
      "   Label: Irony  \n",
      "\n",
      "10. **Non-Irony**: \"I'm not great at cooking, but I'm so grateful for the meal.\"  \n",
      "    Label: Non-Irony  \n",
      "\n",
      "These examples aim to help distinguish between ironic and non-ironic statements based on their meaning and context.\n"
     ]
    }
   ],
   "source": [
    "prompt =\"\"\"\\\n",
    "Produce 10 examples for detecting irony in written text. Examples are categorized as either \"irony\" or \"non-irony\". \\\n",
    "Produce 5 examples  for \"irony\" and 5 examples for \"non-irony\". \n",
    "\n",
    "Use this format for the examples:\n",
    "text: <text>\n",
    "label: <label>\n",
    "\"\"\"\n",
    "generated, delta_t = get_response(prompt, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 35.45\n",
      "GENERATED RESPONSE:\n",
      "Okay, so I need to generate 10 examples of synthetic text for improving an irony detection model. The task is to create exactly 5 irony examples and 5 non-ironicity examples. The format should be something like \"text: [example text] label: [ironicity label].\"\n",
      "\n",
      "First, I should understand what irony is. Irony is when the meaning of something is opposite to what is implied. It often involves a situation where the punchline is the opposite of what is actually happening. For example, \"What do you mean when you say I'm good at cooking?\" is ironic because it's a play on words.\n",
      "\n",
      "I need to create examples that are either ironic or non-ironic. The user provided two examples: one labeled as irony and one as non-ironicity. Let me look at those.\n",
      "\n",
      "In the first example, \"seeing ppl walking w/ crutches makes me really excited for the next 3 weeks of my life\" is labeled as irony. The context is about someone excited about the future, and the action (walking with crutches) is a play on words. \"Walking with crutches\" could be a pun, making the text ironic.\n",
      "\n",
      "The second example, \"look for the girl with the broken smile, ask her if she wants to stay while, and she will be loved. ðŸ’•ðŸŽµ\" is labeled as non-ironicity. It's a straightforward scenario where the person is looking for someone and hopes she'll stay, and the emojis and symbols are just for emphasis.\n",
      "\n",
      "I need to come up with 5 irony examples. Let me think of different scenarios where the situation is the opposite of what's implied. Maybe a situation where the text is trying to convey something that doesn't make sense or where the punchline is opposite.\n",
      "\n",
      "For the first irony example, perhaps a situation where the text is implying something that doesn't happen. For example, \"What if you saw a car parked on a hill?\" That's a classic irony because you'd think the car would fall, but it's parked, so it's a play on words.\n",
      "\n",
      "Another idea: \"If you see a bird in the sky, it's not going to be a sunset.\" This is a classic irony because the bird is in the sky, not on the ground, so it's not a sunset.\n",
      "\n",
      "Wait, maybe I should think of more varied examples. Let me try to come up with some.\n",
      "\n",
      "1. \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" This is a strong example of irony.\n",
      "\n",
      "2. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" This is a play on words where \"drawstring\" is like a bow, so it's ironic.\n",
      "\n",
      "3. \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" (Same as the first one, maybe too similar. Let me think of a different one.)\n",
      "\n",
      "4. \"If you see a bird in the sky, it's not going to be a sunset.\" (Already thought of this.)\n",
      "\n",
      "5. \"What if you saw a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Same as the second one.)\n",
      "\n",
      "Hmm, I need to come up with 5 unique ones. Let me brainstorm again.\n",
      "\n",
      "6. \"What if you saw a car parked on a hill? It's not going to be a parking lot.\" This is a play on words where \"parking lot\" is a flat area, while \"hill\" is elevated, so it's ironic.\n",
      "\n",
      "7. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "8. \"What if you saw a bird in the sky, it's not going to be a sunset.\" (Already have this.)\n",
      "\n",
      "9. \"If you see a bus with a candle on it, it's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "10. \"What if you saw a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "Wait, I'm repeating some examples. Maybe I should think of different contexts. Let's try to think outside the box.\n",
      "\n",
      "11. \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "12. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "13. \"What if you saw a bird in the sky, it's not going to be a sunset.\" (Already have this.)\n",
      "\n",
      "14. \"If you see a bus with a candle on it, it's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "15. \"What if you saw a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "Hmm, I'm struggling to come up with new ones. Maybe I should think of different situations where the text is trying to mislead or is the opposite of reality.\n",
      "\n",
      "16. \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "17. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "18. \"What if you saw a bird in the sky, it's not going to be a sunset.\" (Already have this.)\n",
      "\n",
      "19. \"If you see a bus with a candle on it, it's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "20. \"What if you saw a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "This is getting repetitive. Maybe I need to think of different contexts where the text is trying to mislead.\n",
      "\n",
      "21. \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "22. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "23. \"What if you saw a bird in the sky, it's not going to be a sunset.\" (Already have this.)\n",
      "\n",
      "24. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "25. \"What if you saw a bus with a candle on it, it's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "I'm stuck. Maybe I should try to think of more creative examples.\n",
      "\n",
      "26. \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "27. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "28. \"What if you saw a bird in the sky, it's not going to be a sunset.\" (Already have this.)\n",
      "\n",
      "29. \"If you see a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "30. \"What if you saw a bus with a candle on it, it's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "Hmm, I'm not coming up with new examples. Maybe I need to think of different scenarios where the situation is the opposite of what is implied.\n",
      "\n",
      "Let me try this one: \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "Wait, maybe I can think of a situation where the person is expecting something that won't happen. For example, \"What if you saw a bus with a candle on it? That's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "Alternatively, \"If you see a bus with a candle on it, it's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "I think I'm stuck. Maybe I should try to think of different contexts.\n",
      "\n",
      "Let me try this one: \"What if you saw a man with a bow and a drawstring, he's not going to shoot someone. He's just a deer.\" (Already have this.)\n",
      "\n",
      "Alternatively, \"If you see a bus with a candle on it, it's a classic irony because the candle would light the way to the end of the world.\" (Already have this.)\n",
      "\n",
      "I think I need to accept that I'm repeating examples and come up with a few new ones, even if they are similar to the ones I already have.\n",
      "\n",
      "26. \"What if you saw a bus with a candle on it, it's a classic irony because the candle\n"
     ]
    }
   ],
   "source": [
    "# With example for the two classes\n",
    "prompt =f\"\"\"\\\n",
    "Your task is to generate high-quality synthetic examples of ironic and non-ironic text to improve an irony detection model. \\\n",
    "Produce 10 examples for detecting irony in written text. Examples are categorized as either \"irony\" or \"non-irony\". \\\n",
    "Produce exactly 5 examples  for \"irony\" and 5 examples for \"non-irony\". \n",
    "\n",
    "Use this format for generating the data:\n",
    "text: {first_irony}\n",
    "label: irony\n",
    "\n",
    "text: {first_non_irony}\n",
    "label: non-irony\\\n",
    "\"\"\"\n",
    "generated, delta_t = get_response(prompt, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 22.54\n",
      "GENERATED RESPONSE:\n",
      "Okay, so I need to create 10 examples of irony and non-ironic text for a model that detects irony. I have to make exactly 5 for each category. Let me think about how to approach this.\n",
      "\n",
      "First, I should understand what irony is. Irony is when the meaning of a statement is opposite of what it actually says. It often involves contradiction, surprise, or surprise in the other way. For example, \"I love you, but I hate you\" is ironic because it's contradictory.\n",
      "\n",
      "I need to come up with different scenarios where the irony is clear. Let me brainstorm some situations where irony is evident.\n",
      "\n",
      "For the irony examples, I can think of situations where a statement is true, but the speaker is implying it's false, or vice versa. Maybe some scenarios with emotions involved, like someone being surprised but saying the opposite of what they're feeling.\n",
      "\n",
      "Let's start with the irony examples:\n",
      "\n",
      "1. The sun setting while it's still rising. Wait, that's a bit abstract. Maybe a more relatable example: \"I love you, but I hate you.\" That's classic irony.\n",
      "\n",
      "2. A situation where someone is surprised and then clarifies their statement. For example: \"You think you're the best, but you're really not.\"\n",
      "\n",
      "3. A situation with a twist, like a double negative. \"I'm not happy, but I'm happy.\" That's a classic double negative in irony.\n",
      "\n",
      "4. A scenario involving a lie. \"I said I was going to the store, but I didn't.\" That's a lie and the opposite of the truth.\n",
      "\n",
      "5. A situation with a hidden punchline. \"I love this, but I hate it.\" Again, classic irony.\n",
      "\n",
      "Now, for the non-ironic examples, I need to avoid those contradictions. Maybe situations where the statement is factually true and the speaker is stating it truthfully.\n",
      "\n",
      "1. \"The sun is shining.\" That's a fact and true, so non-ironic.\n",
      "\n",
      "2. \"I'm happy.\" That's a positive statement without any contradiction.\n",
      "\n",
      "3. \"The sky is blue.\" Again, a factual statement.\n",
      "\n",
      "4. \"She is happy.\" Another factual and truthful statement.\n",
      "\n",
      "5. \"The movie was great.\" This is a true statement about the movie.\n",
      "\n",
      "Wait, maybe I should think of a bit more variety. Let me try to come up with some more non-ironic examples.\n",
      "\n",
      "6. \"I'm going to the store.\" That's a factual statement about planning to go somewhere.\n",
      "\n",
      "7. \"The movie is bad.\" This is a negative statement, but it's not the opposite of the truth; it's just a fact that the movie is bad.\n",
      "\n",
      "8. \"She doesn't understand.\" That's a negative statement without any contradictory intent.\n",
      "\n",
      "9. \"We're going to the party.\" Another factual statement about an upcoming event.\n",
      "\n",
      "10. \"I'm tired.\" A neutral statement about the state of mind.\n",
      "\n",
      "I think that covers 5 ironies and 5 non-ironics. Each example should clearly show whether it's ironic or not based on the contradiction or lack thereof.\n",
      "</think>\n",
      "\n",
      "Here is a structured presentation of the examples I created, categorized into irony and non-ironic texts:\n",
      "\n",
      "### Irony Examples:\n",
      "1. **Text**: \"I love you, but I hate you.\"  \n",
      "   **Label**: Irony  \n",
      "   **Explanation**: The speaker presents a contradictory statement, implying their feelings are the opposite of what they're expressing.\n",
      "\n",
      "2. **Text**: \"You think you're the best, but you're really not.\"  \n",
      "   **Label**: Irony  \n",
      "   **Explanation**: The statement creates a paradox, suggesting the speaker is surprised but falsely claims to be excellent.\n",
      "\n",
      "3. **Text**: \"I'm not happy, but I'm happy.\"  \n",
      "   **Label**: Irony  \n",
      "   **Explanation**: This is a classic double negative that creates a contradiction, making the statement ironic.\n",
      "\n",
      "4. **Text**: \"I said I was going to the store, but I didn't.\"  \n",
      "   **Label**: Irony  \n",
      "   **Explanation**: The speaker is lying, presenting a false statement that contradicts their actual words.\n",
      "\n",
      "5. **Text**: \"I love this, but I hate it.\"  \n",
      "   **Label**: Irony  \n",
      "   **Explanation**: The speaker is presenting a contradictory statement, suggesting they love something they hate.\n",
      "\n",
      "### Non-Ironic Examples:\n",
      "1. **Text**: \"The sun is shining.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A factual statement that is true and not contradictory.\n",
      "\n",
      "2. **Text**: \"I'm happy.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A positive statement without any implied contradiction.\n",
      "\n",
      "3. **Text**: \"The sky is blue.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A factual statement about the color of the sky, which is true.\n",
      "\n",
      "4. **Text**: \"She is happy.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A statement about the emotional state of a person, which is factual and true.\n",
      "\n",
      "5. **Text**: \"We're going to the party.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A factual statement about an upcoming event, which is true and not contradictory.\n",
      "\n",
      "6. **Text**: \"I'm going to the store.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A factual statement about an upcoming action, which is true.\n",
      "\n",
      "7. **Text**: \"The movie is bad.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A negative statement that is factual and true.\n",
      "\n",
      "8. **Text**: \"She doesn't understand.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A statement about someone's state of mind, which is factual and true.\n",
      "\n",
      "9. **Text**: \"We're going to the party.\"  \n",
      "   **Label**: Non-Ironic  \n",
      "   **Explanation**: A factual statement about an upcoming event, which is true.\n",
      "\n",
      "10. **Text**: \"I'm tired.\"  \n",
      "    **Label**: Non-Ironic  \n",
      "    **Explanation**: A neutral statement about the state of mind, which is factual and true.\n",
      "\n",
      "This categorization ensures that each example is clearly categorized as either ironic or non-ironic based on the presence or absence of contradiction or contradiction in intent.\n"
     ]
    }
   ],
   "source": [
    "# act as a linguist and NLP practitioner\n",
    "prompt =f\"\"\"\\\n",
    "<context>\n",
    "You are an expert linguist and NLP practitioner specializing in irony detection.\n",
    "</context>\n",
    "\n",
    "Your task is to generate high-quality synthetic examples of ironic and non-ironic text to improve an irony detection model. \\\n",
    "Produce 10 examples for detecting irony in written text. Examples are categorized as either \"irony\" or \"non-irony\". \\\n",
    "Produce exactly 5 examples for \"irony\" and 5 examples for \"non-irony\". \n",
    "\n",
    "Use this format for generating the data:\n",
    "text: <text>\n",
    "label: <label>\n",
    "\"\"\"\n",
    "generated, delta_t = get_response(prompt, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 20.04\n",
      "GENERATED RESPONSE:\n",
      "Okay, so I need to create 10 examples of ironic and non-ironic statements, with exactly 5 of each. The user has already provided an example, so I need to make sure I follow that format. Let me think about how to approach this.\n",
      "\n",
      "First, I should understand what makes a statement ironic. Irony occurs when the meaning of the words is opposite to what is implied, often due to the nature of the words or the context. So, I need to identify statements where the effect contradicts the intention or where the situation is inverted.\n",
      "\n",
      "For the ironic examples, I want to look for situations where the words imply something contrary to what is actually meant. Maybe using words that suggest a negative outcome when they shouldn't, or positive when they should be negative, or vice versa.\n",
      "\n",
      "Let me brainstorm some scenarios where irony is common. For example, \"I see a crocodile crossing the road\" is ironic because the presence of a crocodile implies danger, which is the opposite of the speaker's intention. Another example could be a joke where the punchline is the opposite of what's implied by the phrase.\n",
      "\n",
      "I should also consider different contextsâ€”like everyday situations, social media, literature, etc. Each example should be varied to cover a range of scenarios.\n",
      "\n",
      "For non-ironic statements, I need to avoid situations where the words are directly contradictory. Instead, the statements should be straightforward and not imply an opposite meaning. For example, \"She is so happy she almost fell\" is non-ironic because it's just expressing happiness without any implied irony.\n",
      "\n",
      "I need to ensure that I have 5 ironic and 5 non-ironic examples. Let me try to come up with some.\n",
      "\n",
      "1. ironic: \"I see ppl walking w/ crutches makes me really excited for the next 3 weeks of my life.\" This is ironic because walking with crutches suggests independence, which is the opposite of being dependent on them.\n",
      "\n",
      "2. Non-ironic: \"She is so happy she almost fell.\" It's non-ironic because it's just expressing happiness without any implied irony.\n",
      "\n",
      "3. ironic: \"The company is hiring more for the role, but they said they won't. ðŸ˜•.\" This is ironic because the announcement of higher numbers contradicts the company's word.\n",
      "\n",
      "4. Non-ironic: \"He's been to Paris many times. That's one of the best travel destinations in the world.\" It's straightforward and doesn't imply any irony.\n",
      "\n",
      "5. ironic: \"I saw a bird in the garden. It's singing. ðŸŒŸ.\" This is ironic because a bird singing is the opposite of what the speaker sees, implying a different situation.\n",
      "\n",
      "6. Non-ironic: \"She loves her job. She told me that, but I still work hard. ðŸ’•.\" It's non-ironic because it's just stating her job satisfaction without any implied irony.\n",
      "\n",
      "7. ironic: \"The weather is freezing tonight. It will be cold, so I won't go out.\" This is ironic because the cold weather contradicts the speaker's desire to go out.\n",
      "\n",
      "8. Non-ironic: \"They always have the best food in town. So why don't I try it?\" It's straightforward and not implying any irony.\n",
      "\n",
      "9. ironic: \"I heard a lot of news about the project. But actually, it's going to be a disaster. ðŸš¨.\" This is ironic because the news contradicts the actual situation.\n",
      "\n",
      "10. Non-ironic: \"She likes to cook. So why don't I make a meal for you?\" It's non-ironic because it's just stating a fact without any implied irony.\n",
      "\n",
      "I think these examples cover a variety of contexts and scenarios, ensuring that I have both ironic and non-ironic statements. I should double-check each one to make sure they fit the criteria.\n",
      "</think>\n",
      "\n",
      "Here is the organized list of examples, categorized into ironic and non-ironic statements:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"text\": \"I see ppl walking w/ crutches makes me really excited for the next 3 weeks of my life\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She is so happy she almost fell\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The company is hiring more for the role, but they said they won't. ðŸ˜•ðŸŽµ\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"He's been to Paris many times. That's one of the best travel destinations in the world\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I saw a bird in the garden. It's singing. ðŸŒŸ\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She loves her job. She told me that, but I still work hard. ðŸ’•\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The weather is freezing tonight. It will be cold, so I won't go out\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"They always have the best food in town. So why don't I try it?\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I heard a lot of news about the project. But actually, it's going to be a disaster. ðŸš¨\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She likes to cook. So why don't I make a meal for you?\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Logged 10 examples to synthetic_data/semevalirony_log.json. Time taken: 20.04 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP practitioner specializing in irony detection. \\\n",
    "Your task is to generate **10 high-quality examples** of ironic and non-ironic statements, \\\n",
    "with **5 ironic** and **5 non-ironic** examples across different contexts.\n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return the final result into a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": \"{first_irony}\", \"label\": \"ironic\"}},\n",
    "    {{\"text\": \"{first_non_irony}\", \"label\": \"non-ironic\"}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer)\n",
    "synthetic_data = response2json(response)\n",
    "log_synthetic_data(model_name, \"baseline\", prompt, synthetic_data, delta_t, output_file=log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Targeted synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 13.82\n",
      "GENERATED RESPONSE:\n",
      "Okay, so I need to figure out the key linguistic and semantic phenomena that are important for detecting irony in text. I'm a bit new to this, so I'll start by breaking down what irony is. Irony is when the intended meaning of two statements is opposite, often because of wordplay or ambiguity. Examples include \"Why are you here?\" and \"Why are you leaving?\" which are contradictory.\n",
      "\n",
      "First, I should think about the grammatical aspects. Maybe things like question words, statements, and how they relate to each other. For instance, if someone is asking a question and then says \"I'm done,\" that's irony because the question and response are contradictory.\n",
      "\n",
      "Then, there's the concept of contradiction. When two statements are opposites. But that's too broad. I need more specific terms. Maybe the relationship between the subject and predicate in each statement. If the subject is the same but the predicate is contradictory, that's a clue.\n",
      "\n",
      "I also remember something about inverted questions. When a question is followed by a statement that's the opposite of what the question implies. Like, \"What time is your meeting?\" followed by \"I'm not in the meeting.\" That's a classic example.\n",
      "\n",
      "Another idea is the use of contrary clauses. For example, \"Because you're busy, I can't help you.\" Here, the subject of the second clause is contrary to the first statement, creating a paradox.\n",
      "\n",
      "Paradoxes are a subset of irony where the statements contradict each other. So, identifying when two contradictory statements are made is key. But I also need to consider if the contradiction is intentional or just a coincidence.\n",
      "\n",
      "The structure of the sentences might be important too. If the subject and predicate of each statement are swapped, that can be a sign of irony. Like, \"I'm not coming\" instead of \"I'm coming.\"\n",
      "\n",
      "There's also the concept of inversion of the subject and predicate in the second statement. If the first statement is about a subject and the second is about the predicate being opposite, that's irony. For example, \"I'm not going to the party\" and \"I'm going to the party.\"\n",
      "\n",
      "Another thing is the use of the word \"because\" or \"because of\" to introduce a reason, which often leads to a contrary conclusion. Like, \"Because I'm busy, I can't help you.\"\n",
      "\n",
      "I also think about the relationship between the subjects and predicates. If the subject of one is the opposite of the other, that can create a paradox. For instance, \"I don't like this\" and \"I like this.\"\n",
      "\n",
      "Lastly, the use of the word \"because\" to create a reason for the contrary conclusion is another key phenomenon. It shows that the second statement is the opposite of the first.\n",
      "\n",
      "Wait, I think I might have missed something. There's the concept of inverted clauses. If the subject and predicate are swapped in the second statement, that's a clear inversion. Like, \"I'm not coming to the party\" instead of \"I'm coming to the party.\"\n",
      "\n",
      "Also, the use of the word \"because\" can be a red herring, but in this case, it's important to identify when it's used to create irony. So, the structure of the sentences, the subject-predicate relationships, and the inversion of clauses are all key phenomena.\n",
      "\n",
      "I should make sure I'm not missing any other related concepts. Maybe the concept of a \"contradictory statement,\" but that's too general. The specific phenomena I listed seem to cover the main points. I think these are the main ones that need to be considered for accurately detecting irony.\n",
      "</think>\n",
      "\n",
      "- Contradiction in Statements\n",
      "- Inverted Question Structure\n",
      "- Contrary Clauses\n",
      "- Paradoxical Relationships\n",
      "- Subject-Predicate Inversion\n",
      "- Use of \"Because\" for Contradictory Conclusions\n",
      "- Inverted Clauses\n",
      "- Wordplay and Wordplay Structure\n",
      "- Inverted Question and Response\n",
      "- Subject-Predicate Relationship\n",
      "- Use of \"Because\" to Create Reasoning\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguistics and NLP practitioner. \\\n",
    "List all key linguistic and semantic phenomena that must be considered for an irony detection model to perform accurately. \\\n",
    "Provide only the names of these key concepts as a structured list, without explanations.\n",
    "\n",
    "Return the list in a simple bullet-point format, each bullet point must start with a dash \"-\".\\\n",
    "\"\"\"\n",
    "\n",
    "response, delta_t_0 = get_response(prompt, model, tokenizer)\n",
    "\n",
    "# Extract bullet points\n",
    "bullets = re.findall(r\"- (.+)\", response)\n",
    "bullets = [b.strip() for b in bullets]  # Remove leading/trailing whites\n",
    "\n",
    "# Convert to CSV string\n",
    "csv_string = \", \".join(bullets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 14.32\n",
      "GENERATED RESPONSE:\n",
      "Okay, so the user has asked me to generate 10 sentences that illustrate different types of irony. They provided a clear structure with 5 ironic and 5 non-ironic sentences. I need to make sure I understand each type of irony they're looking for.\n",
      "\n",
      "First, I'll break down each category. For ironic sentences, I should focus on situations where the irony is direct and surprising. Maybe something about walking with chutes, as they mentioned. Then, inverted question structures, so I'll need sentences where the question is phrased backwards but still makes sense.\n",
      "\n",
      "Contrary clauses are sentences where the usual structure is flipped. I'll have to think of scenarios where the opposite of what's stated makes sense. Paradoxical relationships could involve situations where two unrelated actions lead to a surprising conclusion, like a car breaking down and being repaired.\n",
      "\n",
      "Subject-predicate inversion is a bit tricky. I'll need to switch the subject and predicate in a way that creates a twist. Use of \"because\" for contradictory conclusions will require sentences where the explanation is opposite of what's stated. Inverted clauses are a bit confusing, so I'll have to craft sentences where the usual structure is reversed but still makes sense.\n",
      "\n",
      "Wordplay is where words are used in a clever way, like \"I'm so sad I can't even breathe.\" Inverted question and response are straightforward, just reversing the question and answer. Subject-predicate relationship is a bit confusing, so I'll need to find examples where the subject and predicate are swapped in a surprising way. Finally, using \"because\" to create reasoning sentences will require the explanation to be the opposite of what's stated.\n",
      "\n",
      "I'll start by listing sentences for each category, ensuring they're realistic. For ironic ones, maybe something about a car getting stuck and being repaired. For non-ironic, perhaps a funny situation like a broken smile or a joke. I'll make sure each sentence meets the criteria and is realistic.\n",
      "\n",
      "I need to double-check each sentence to ensure it fits the required structure and that the irony is correctly identified. Maybe I'll go through each category one by one, creating sentences that fit the user's criteria. Once I have all 10, I'll format them into a JSON array as specified.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"text\": \"Seeing ppl walking with crutches makes me really excited for the next 3 weeks of my life\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The girl with the broken smile is so cute, but I wonder if she'll ever look back at me.\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"Why did the car break down? Because the parking lot was closed.\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I asked her if she wants to stay, and she said she won't, but she's so beautiful.\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The boy didn't know how to say no, so he just kept walking away.\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The girl's smile was broken, but she still looked so cute.\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"Because I'm so tired, I can't even breathe.\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The boy thought he was the one, but it turns out he was just a regular guy.\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The car broke down and was fixed, but the road was closed.\",\n",
      "        \"label\": \"ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The girl's eyes were broken, but she still laughed.\",\n",
      "        \"label\": \"non-ironic\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"Because I'm so sad, I can't even talk.\",\n",
      "        \"label\": \"ironic\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "Generate 10 realistic sentences illustrating irony detection examples involving {csv_string}. Ensure that:\n",
    "- 5 sentences are **ironic**.\n",
    "- 5 sentences are **non-ironic**.\n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return **only** a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": \"{first_irony}\", \"label\": \"ironic\"}},\n",
    "    {{\"text\": \"{first_non_irony}\", \"label\": \"non-ironic\"}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer)\n",
    "# synthetic_data = response2json(response)\n",
    "# log_synthetic_data(model_name, \"targeted\", prompt, synthetic_data, delta_t, output_file=log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted synthetic data with Chat-GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 19.94\n",
      "GENERATED RESPONSE:\n",
      "Okay, so I need to generate 10 realistic sentences that illustrate irony using the provided phenomena. Let me break down the requirements.\n",
      "\n",
      "First, I should understand the phenomena: linguistic, semantic, and contextual. The user provided four categories for each, so I'll need to pick one category for each example. \n",
      "\n",
      "Linguistic Phenomena include unusual word choice, negation, punctuation, complex sentence structures, and contrastive conjunctions. The semantic phenomena are contextual incongruity, polarity reversal, hyperbole, and sarcasm. Contextual cues are world knowledge, speaker intent, and discourse contrast.\n",
      "\n",
      "I need to create sentences that fit one of these categories. Let's brainstorm a variety of examples.\n",
      "\n",
      "1. **Contrastive Conjunctions**: Maybe a statement that reverses the obvious. Like saying \"I love him, but he loves me\" using \"but\" to contradict. So \"I love him, but he loves me. You should never be in his presence.\" Here, \"but\" is a contrastive conjunction.\n",
      "\n",
      "2. **Lexical Choice**: Using an unusual word. \"I'm so tired, I almost want to scream. But I keep talking to myself, pretending I'm not too tired.\" Here, \"tired\" is exaggerated.\n",
      "\n",
      "3. **Punctuation**: Using ellipses or quotes for emphasis. \"She said, 'I'm not sure what to do.' But she didn't elaborate. She just said, 'I'm not sure what to do.'\" The ellipsis adds emphasis.\n",
      "\n",
      "4. **World Knowledge**: Using cultural references. \"In the land of the north, it's said that the wind blows from the north. But in the south, the wind blows from the south. So, the wind must blow from both places!\" This uses a known fact from different cultures.\n",
      "\n",
      "5. **Lexical Choice**: Using a word that's not common. \"The sky is a beautiful place. But I find it hard to believe it's so blue. Maybe it's just a hallucination.\" Here, \"beautiful\" is unusual.\n",
      "\n",
      "6. **Punctuation**: Using a quote to emphasize a point. \"I said, 'I love him,' but he said, 'I love me.' So, we're both in love.\" The quote adds emphasis to the comparison.\n",
      "\n",
      "7. **Contextual Incongruity**: Discrepancy between words and context. \"She said, 'I'm going to the store.' But she didn't mention where the store is. I wonder where she went to the store.\" The context is missing information.\n",
      "\n",
      "8. **Contrastive Conjunctions**: Using \"but\" again. \"She told me, 'I love him.' But when I tried to meet him, he didn't come. So, maybe he's not who he seemed.\" This uses \"but\" to contradict the initial statement.\n",
      "\n",
      "9. **World Knowledge**: Using a historical fact. \"In ancient Rome, a famous story says that the last man to live was a man named Marcus Aurelius. But in modern times, no one has ever lived as long as he did. So, maybe he's not the last man.\" This uses a historical fact about Marcus Aurelius.\n",
      "\n",
      "10. **Lexical Choice**: Using a word that's not commonly used. \"The river flows gently, almost like a whisper. But I feel the current is too strong. Maybe it's just a slow-moving river.\" Here, \"glush\" is a term I'm not sure about, but it's a word used in a specific context.\n",
      "\n",
      "I think these examples cover a good range of the phenomena and convey irony in each case. Each example should clearly show the irony by using the phenomena mentioned.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\"text\": \"I love him, but he loves me. You should never be in his presence.\", \"label\": \"irony\"},\n",
      "    {\"text\": \"I'm so tired, I almost want to scream. But I keep talking to myself, pretending I'm not too tired.\", \"label\": \"irony\"},\n",
      "    {\"text\": \"She said, 'I'm not sure what to do.' But she didn't elaborate. She just said, 'I'm not sure what to do.'\"}, {\"text\": \"In the land of the north, it's said that the wind blows from the north. But in the south, the wind blows from the south. So, the wind must blow from both places!\", \"label\": \"irony\"},\n",
      "    {\"text\": \"The sky is a beautiful place. But I find it hard to believe it's so blue. Maybe it's just a hallucination.\", \"label\": \"irony\"},\n",
      "    {\"text\": \"I said, 'I love him,' but he said, 'I love me.' So, maybe he's not who he seemed.\", \"label\": \"irony\"},\n",
      "    {\"text\": \"She told me, 'I love him.' But when I tried to meet him, he didn't come. So, maybe he's not who he seemed.\", \"label\": \"irony\"},\n",
      "    {\"text\": \"The river flows gently, almost like a whisper. But I feel the current is too strong. Maybe it's just a slow-moving river.\", \"label\": \"irony\"},\n",
      "    {\"text\": \"In ancient Rome, a famous story says that the last man to live was a man named Marcus Aurelius. But in modern times, no one has ever lived as long as he did. So, maybe he's not the last man.\", \"label\": \"irony\"},\n",
      "    {\"text\": \"The river flows gently, almost like a whisper. But I feel the current is too strong. Maybe it's just a slow-moving river.\", \"label\": \"irony\"}\n",
      "]\n",
      "```\n",
      "Logged 10 examples to synthetic_data/semevalirony_log.json. Time taken: 19.94 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP practitioner. \\\n",
    "Generate 10 realistic sentences illustrating irony detection examples.\\\n",
    "For each example specify the label as either \"irony\" or \"non-irony\".\n",
    "\n",
    "### **Consider the following Phenomena:**\n",
    "- **Linguistic Phenomena**  \n",
    "    - Lexical Choice: Unusual or exaggerated word use.  \n",
    "    - Negation: Statements that negate obvious facts.  \n",
    "    - Punctuation: Use of exclamation marks, ellipses, or quotes for emphasis.  \n",
    "    - Syntactic Cues: Unusual or complex sentence structures.  \n",
    "    - Contrastive Conjunctions: Use of \"but,\" \"however,\" to signal contradiction.  \n",
    "\n",
    "- **Semantic Phenomena**  \n",
    "    - Contextual Incongruity: Discrepancy between words and context.  \n",
    "    - Polarity Reversal: Positive words with negative intent, or vice versa.  \n",
    "    - Hyperbole & Understatement: Exaggeration or minimization for effect.  \n",
    "    - Sarcasm: Mocking statements implying the opposite meaning.  \n",
    "\n",
    "- **Contextual Cues**  \n",
    "    - World Knowledge: Understanding cultural or situational references.  \n",
    "    - Speaker Intent: Inferring the true intention behind words.  \n",
    "    - Discourse Contrast: Contradictions across multiple sentences.  \n",
    "\n",
    "### **Output Format (JSON)**\n",
    "For each example specify the label as either \"irony\" or \"non-irony\".\n",
    "Return only a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": <text>, \"label\": <label>}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer)\n",
    "synthetic_data = response2json(response)\n",
    "log_synthetic_data(model_name, \"targeted\", prompt, synthetic_data, delta_t, output_file=log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Targeted + Tags linguistic phenomena "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME TAKEN: 24.04\n",
      "GENERATED RESPONSE:\n",
      "Okay, so I need to create 10 examples of irony and non-irony sentences based on the provided phenomena. Let me first make sure I understand the criteria for each category.\n",
      "\n",
      "Starting with the label \"irony.\" I know irony is when the meaning of the words is opposite to their literal meaning. Examples could involve exaggerated words, negations, complex sentences, or contextually inconsistent statements.\n",
      "\n",
      "For \"non-irony,\" it's when the irony is subtle or comes from context or word choice that doesn't change the literal meaning. Maybe using a word without the right connotation or a situation where the irony is implied.\n",
      "\n",
      "Now, looking at the phenomena:\n",
      "\n",
      "1. **Lexical Choice**: Using unusual words. For irony, maybe a word that's not commonly used but conveys strong emotions.\n",
      "2. **Negation**: Statements that contradict obvious facts. For example, \"I don't know if I'm right.\"\n",
      "3. **Punctuation**: Using exclamation marks or ellipses to emphasize. Irony might come from the emphasis.\n",
      "4. **Syntactic Cues**: Complex sentences. Maybe a complex structure that's not typical.\n",
      "5. **Contrastive Conjunctions**: Words like \"but\" or \"however.\" Irony might come from the choice of words.\n",
      "6. **Semantic Phenomena**: Contextual inconsistency. The word doesn't fit the context.\n",
      "7. **Polarity Reversal**: Words with opposite intent. Like \"happy\" and \"sad.\"\n",
      "8. **Hyperbole & Understatement**: Using exaggerated or minimized statements. Irony comes from the emphasis.\n",
      "9. **Sarcasm**: Mocking statements. This is a clear form of irony.\n",
      "10. **Contextual Cues**: Cultural references or speaker intent. Maybe a situation where the speaker is trying to imply something.\n",
      "\n",
      "I need to come up with 10 sentences. Let me brainstorm some examples.\n",
      "\n",
      "1. **Irony Example 1**: \"I don't know if I'm right.\" Here, negation is used, and the contradiction in meaning is clear.\n",
      "2. **Non-IrONY Example 1**: \"We're going to the beach tomorrow. How about if we go alone?\" This uses a contrastive conjunction but doesn't imply anything opposite.\n",
      "3. **Irony Example 2**: \"That's the most delicious thing I've ever had.\" Hyperbole and understatement are used. The irony is in the contradiction between the literal meaning and the emotional impact.\n",
      "4. **Non-IrONY Example 2**: \"She's always late, but she's a great cook.\" Polarity reversal, but it's not clear if it's ironic.\n",
      "5. **Irony Example 3**: \"I can't believe I didn't see the movie.\" Negation and the contradiction in meaning.\n",
      "6. **Non-IrONY Example 3**: \"The sun is shining bright today.\" Contextual inconsistency; the word \"shining\" might imply something else.\n",
      "7. **Irony Example 4**: \"She always wins the argument.\" Sarcasm, where the word \"wins\" is a lie.\n",
      "8. **Non-IrONY Example 4**: \"He's very tall and thin.\" Contextual inconsistency; \"tall and thin\" might imply something else.\n",
      "9. **Irony Example 5**: \"I think I'm over my head.\" Negation and context.\n",
      "10. **Non-IrONY Example 5**: \"The movie was great, but we left early.\" Contextual inconsistency; \"great\" and \"left early\" might imply different things.\n",
      "\n",
      "Wait, some of these might not be perfect. Let me refine them.\n",
      "\n",
      "For **Irony Example 1**, maybe \"I don't know if I'm right.\" is better.\n",
      "\n",
      "**Irony Example 2**: \"I can't believe I didn't see the movie.\" Maybe \"can't believe\" is the irony, but the context is clear.\n",
      "\n",
      "**Irony Example 3**: \"She always wins the argument.\" Maybe \"wins\" is a lie, which is ironic.\n",
      "\n",
      "**Non-Irony Example 1**: \"We're going to the beach tomorrow. How about if we go alone?\" It's contextually inconsistent but not necessarily ironic.\n",
      "\n",
      "**Non-Irony Example 2**: \"She's always late, but she's a great cook.\" Maybe it's not clear if it's ironic.\n",
      "\n",
      "I think I have a better structure now. Let me list 10 sentences with their labels and phenomena.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"text\": \"I don't know if I'm right.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"negation\", \"contextual inconsistency\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I can't believe I didn't see the movie.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"negation\", \"contextual inconsistency\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She always wins the argument.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"contrastive conjunction\", \"sarcasm\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"We're going to the beach tomorrow. How about if we go alone?\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"contextual inconsistency\", \"polarity reversal\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The sun is shining bright today.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"negation\", \"contradiction in meaning\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I can't believe I didn't see the movie.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"negation\", \"contextual inconsistency\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"She always wins the argument.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"contradiction in meaning\", \"sarcasm\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"We're going to the beach tomorrow. How about if we go alone?\",\n",
      "        \"label\": \"non-irony\",\n",
      "        \"phenomena\": [\"contextual inconsistency\", \"polarity reversal\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"The sun is shining bright today.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"negation\", \"contradiction in meaning\"]\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"I think I'm over my head.\",\n",
      "        \"label\": \"irony\",\n",
      "        \"phenomena\": [\"negation\", \"contrual inconsistency\"]\n",
      "    }\n",
      "]\n",
      "```\n",
      "Logged 10 examples to synthetic_data/semevalirony_log.json. Time taken: 24.04 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP specialist in sarcasm and irony detection. \\\n",
    "Generate 10 realistic sentences illustrating irony detection examples.\\\n",
    "For each example specify the label as either \"irony\" or \"non-irony\", give examples for both of them. And also list the key phenomena it covers.\n",
    "\n",
    "### **Consider the following Phenomena:**\n",
    "- **Linguistic Phenomena**  \n",
    "    - Lexical Choice: Unusual or exaggerated word use.  \n",
    "    - Negation: Statements that negate obvious facts.  \n",
    "    - Punctuation: Use of exclamation marks, ellipses, or quotes for emphasis.  \n",
    "    - Syntactic Cues: Unusual or complex sentence structures.  \n",
    "    - Contrastive Conjunctions: Use of \"but,\" \"however,\" to signal contradiction.  \n",
    "\n",
    "- **Semantic Phenomena**  \n",
    "    - Contextual Incongruity: Discrepancy between words and context.  \n",
    "    - Polarity Reversal: Positive words with negative intent, or vice versa.  \n",
    "    - Hyperbole & Understatement: Exaggeration or minimization for effect.  \n",
    "    - Sarcasm: Mocking statements implying the opposite meaning.  \n",
    "\n",
    "- **Contextual Cues**  \n",
    "    - World Knowledge: Understanding cultural or situational references.  \n",
    "    - Speaker Intent: Inferring the true intention behind words.  \n",
    "    - Discourse Contrast: Contradictions across multiple sentences.  \n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return only a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": <text>, \"label\": <corresponding label>, \"phenomena\": [\"<phenomenon1>\", \"<phenomenon2>\", ...]}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "response, delta_t = get_response(prompt, model, tokenizer)\n",
    "synthetic_data = response2json(response)\n",
    "log_synthetic_data(model_name, \"targeted + linguistic tags\", prompt, synthetic_data, delta_t, output_file=log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of data generated by Chat-GPT\n",
    "\n",
    "\"text\": \"Oh, great! Another rainy day for my outdoor event. Just what I needed!\",  \n",
    "\"label\": \"irony\",  \n",
    "\"phenomena\": [\"Punctuation\", \"Contextual Incongruity\", \"Sarcasm\"]  \n",
    "\n",
    "\"text\": \"I love waiting in long lines at the grocery store. Itâ€™s my favorite pastime!\",  \n",
    "\"label\": \"irony\",  \n",
    "\"phenomena\": [\"Lexical Choice\", \"Sarcasm\"]  \n",
    "\n",
    "\"text\": \"Iâ€™m really excited to spend the weekend doing absolutely nothing.\",  \n",
    "\"label\": \"irony\",  \n",
    "\"phenomena\": [\"Lexical Choice\", \"Hyperbole\", \"Sarcasm\"]  \n",
    "\n",
    "\"text\": \"The movie was so bad, I could barely keep my eyes open. A masterpiece, truly.\",  \n",
    "\"label\": \"irony\",  \n",
    "\"phenomena\": [\"Polarity Reversal\", \"Sarcasm\", \"Contextual Incongruity\"]  \n",
    "\n",
    "\"text\": \"Heâ€™s the best driver I know. Heâ€™s never gotten into an accident... oh wait, he has.\"  \n",
    "\"label\": \"irony\",  \n",
    "\"phenomena\": [\"Contrastive Conjunctions\", \"Contextual Incongruity\", \"Sarcasm\"]  \n",
    "\n",
    "\"text\": \"Sure, because skipping breakfast is such a great idea for energy.\"  \n",
    "\"label\": \"irony\",  \n",
    "\"phenomena\": [\"Sarcasm\", \"Contextual Incongruity\"]  \n",
    "\n",
    "\"text\": \"Iâ€™m excited to try this new restaurant tonight. Itâ€™s my favorite place to eat.\",  \n",
    "\"label\": \"non-irony\",  \n",
    "\"phenomena\": [\"Lexical Choice\"]  \n",
    "\n",
    "\"text\": \"She finished her work on time, and it was a great accomplishment for the team.\",  \n",
    "\"label\": \"non-irony\",  \n",
    "\"phenomena\": [\"Contextual Incongruity\"]  \n",
    "\n",
    "\"text\": \"Sure, skipping breakfast is a great idea for boosting energy!\",  \n",
    "\"label\": \"irony\",  \n",
    "\"phenomena\": [\"Sarcasm\", \"Contextual Incongruity\"]  \n",
    "\n",
    "\"text\": \"The meeting went well, and we made great progress on the project.\",  \n",
    "\"label\": \"non-irony\",  \n",
    "\"phenomena\": [\"Lexical Choice\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
