{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# CHANGE WORKING DIRECTORY TO ROOT\n",
    "current_dir = os.path.basename(os.getcwd())\n",
    "if current_dir == \"src\":\n",
    "    os.chdir(\"..\") # Move up by 1\n",
    "elif os.path.basename(os.getcwd()) == \"bai-thesis-nlp\":  \n",
    "    pass # If already at root, stay there\n",
    "else:\n",
    "    os.chdir(\"../..\") # Move up by 2 otherwise\n",
    "    \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "from src._utils._helpers import log_synthetic_data, response2json, get_response, set_seed, clear_cuda_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000_train</td>\n",
       "      <td>Hartford executive #39;s stock sale probed</td>\n",
       "      <td>New York AG is investigating the timing of a s...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_train</td>\n",
       "      <td>Cool Batman Photo!</td>\n",
       "      <td>In related news, it was announced yesterday th...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002_train</td>\n",
       "      <td>Stocky Monkey in Himalayas Becomes Newest Prim...</td>\n",
       "      <td>Scientists from India working in the Himalayas...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003_train</td>\n",
       "      <td>Bush, Kerry Don''t Worry About Tech</td>\n",
       "      <td>Election Day is less than two weeks away, but ...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004_train</td>\n",
       "      <td>The Teeming Crowd in Video Games</td>\n",
       "      <td>Jeffrey Griffiths, the president and chief exe...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1  \\\n",
       "0  1000_train         Hartford executive #39;s stock sale probed   \n",
       "1  1001_train                                 Cool Batman Photo!   \n",
       "2  1002_train  Stocky Monkey in Himalayas Becomes Newest Prim...   \n",
       "3  1003_train                Bush, Kerry Don''t Worry About Tech   \n",
       "4  1004_train                   The Teeming Crowd in Video Games   \n",
       "\n",
       "                                                text     label  \n",
       "0  New York AG is investigating the timing of a s...  Business  \n",
       "1  In related news, it was announced yesterday th...  Sci/Tech  \n",
       "2  Scientists from India working in the Himalayas...  Sci/Tech  \n",
       "3  Election Day is less than two weeks away, but ...  Sci/Tech  \n",
       "4  Jeffrey Griffiths, the president and chief exe...  Sci/Tech  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: Business, Sci/Tech, Sports, World\n",
      "Label: Business\n",
      "Text: New York AG is investigating the timing of a sale by Thomas Marra; company reports higher 3Q. NEW YORK (Reuters) - The Hartford Financial Services Group Inc.\n",
      "\n",
      "Label: Sci/Tech\n",
      "Text: In related news, it was announced yesterday that Warner Bros. Interactive Entertainment, DC Comics and Electronic Arts will bring a Batman Begins videogame tie-in.\n",
      "\n",
      "Label: Sports\n",
      "Text: Lindsay Davenport #39;s world number one ranking is in doubt after she failed to make the finals of the WTA Tour Championships in Los Angeles.\n",
      "\n",
      "Label: World\n",
      "Text:  JERUSALEM (Reuters) - Israeli Prime Minister Ariel Sharon  accused far-rightists Sunday of trying to incite civil war over  his plan to withdraw from the occupied Gaza Strip and called  for measures to curb such groups.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the folder to save the synthetic data\n",
    "folder_name = \"synthetic_data/logs\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# file where the logs will be saved\n",
    "log_file_path = folder_name + \"/agnews_log.json\"\n",
    "RECREATE_LOG = False\n",
    "if os.path.exists(log_file_path) and RECREATE_LOG:\n",
    "    os.remove(log_file_path) # recreate from scratch\n",
    "\n",
    "# DEVICE\n",
    "device = 'cuda:0'\n",
    "\n",
    "# DATA\n",
    "df = pd.read_csv(\"real_data/train/agnewstrainAll.csv\")\n",
    "df = df.rename(columns={\"2\": \"text\", \"3\": \"label\"})\n",
    "display(df.head())\n",
    "\n",
    "labels_lst = df['label'].unique()\n",
    "labels_str = \", \".join(labels_lst)\n",
    "labels_str_bullet = \"\\n\".join([f\"- **{name}**\" for name in labels_lst])\n",
    "print(f\"Labels: {labels_str}\")\n",
    "\n",
    "# Print the first example for each label\n",
    "examples = []\n",
    "for label in labels_lst:\n",
    "    example = (df[df['label'] == label].iloc[0]).loc['text']\n",
    "    examples.append(example)\n",
    "    print(f\"Label: {label}\\nText: {example}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src._utils._generate_dataset import generate_synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_length': 20, 'max_new_tokens': None, 'min_length': 0, 'min_new_tokens': None, 'early_stopping': False, 'max_time': None, 'stop_strings': None, 'do_sample': True, 'num_beams': 1, 'num_beam_groups': 1, 'penalty_alpha': None, 'dola_layers': None, 'use_cache': True, 'cache_implementation': None, 'cache_config': None, 'return_legacy_cache': None, 'temperature': 0.6, 'top_k': 50, 'top_p': 0.95, 'min_p': None, 'typical_p': 1.0, 'epsilon_cutoff': 0.0, 'eta_cutoff': 0.0, 'diversity_penalty': 0.0, 'repetition_penalty': 1.0, 'encoder_repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'bad_words_ids': None, 'force_words_ids': None, 'renormalize_logits': False, 'constraints': None, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'forced_decoder_ids': None, 'sequence_bias': None, 'token_healing': False, 'guidance_scale': None, 'low_memory': None, 'watermarking_config': None, 'num_return_sequences': 1, 'output_attentions': False, 'output_hidden_states': False, 'output_scores': False, 'output_logits': None, 'return_dict_in_generate': False, 'pad_token_id': 151643, 'bos_token_id': 151646, 'eos_token_id': 151643, 'encoder_no_repeat_ngram_size': 0, 'decoder_start_token_id': None, 'is_assistant': False, 'num_assistant_tokens': 20, 'num_assistant_tokens_schedule': 'constant', 'assistant_confidence_threshold': 0.4, 'prompt_lookup_num_tokens': None, 'max_matching_ngram_size': None, 'assistant_early_exit': None, 'assistant_lookbehind': 10, 'target_lookbehind': 10, 'disable_compile': False, 'generation_kwargs': {}, '_from_model_config': True, 'transformers_version': '4.49.0'}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=device,\n",
    "    attn_implementation='flash_attention_2',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(model.generation_config.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do_sample': True, 'temperature': 0.6, 'top_p': 0.95, 'pad_token_id': 151643, 'bos_token_id': 151646, 'eos_token_id': 151643, '_from_model_config': True, 'transformers_version': '4.49.0'}\n",
      "GenerationConfig {\n",
      "  \"bos_token_id\": 151646,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.95\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.generation_config.to_diff_dict())\n",
    "print(model.generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating batch 1\n",
      "Batch 1 generated with 10 examples.\n",
      "Generating batch 2\n",
      "Batch 2 generated with 10 examples.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\\\n",
    "You are an expert linguist and NLP specialist in sarcasm and irony detection. \\\n",
    "Generate 10 realistic sentences illustrating irony detection examples.\\\n",
    "For each example specify the label as either \"irony\" or \"non-irony\", give examples for both of them. And also list the key phenomena it covers.\n",
    "\n",
    "### **Consider the following Phenomena:**\n",
    "- **Linguistic Phenomena**  \n",
    "    - Lexical Choice: Unusual or exaggerated word use.  \n",
    "    - Negation: Statements that negate obvious facts.  \n",
    "    - Punctuation: Use of exclamation marks, ellipses, or quotes for emphasis.  \n",
    "    - Syntactic Cues: Unusual or complex sentence structures.  \n",
    "    - Contrastive Conjunctions: Use of \"but,\" \"however,\" to signal contradiction.  \n",
    "\n",
    "- **Semantic Phenomena**  \n",
    "    - Contextual Incongruity: Discrepancy between words and context.  \n",
    "    - Polarity Reversal: Positive words with negative intent, or vice versa.  \n",
    "    - Hyperbole & Understatement: Exaggeration or minimization for effect.  \n",
    "    - Sarcasm: Mocking statements implying the opposite meaning.  \n",
    "\n",
    "- **Contextual Cues**  \n",
    "    - World Knowledge: Understanding cultural or situational references.  \n",
    "    - Speaker Intent: Inferring the true intention behind words.  \n",
    "    - Discourse Contrast: Contradictions across multiple sentences.  \n",
    "\n",
    "### **Output Format (JSON)**\n",
    "Return only a valid JSON list in the following structure:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {{\"text\": <text>, \"label\": <corresponding label>, \"phenomena\": [\"<phenomenon1>\", \"<phenomenon2>\", ...]}},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "res = generate_synthetic_data(prompt, 10, model, tokenizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
